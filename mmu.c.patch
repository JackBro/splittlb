--- kernel-untouched/linux-3.19.0/arch/x86/kvm/mmu.c	2016-01-14 15:17:52.000000000 -0800
+++ kernel-tlbsplit/linux-3.19.0/arch/x86/kvm/mmu.c	2016-01-24 13:02:22.740403711 -0800
@@ -41,6 +41,7 @@
 #include <asm/cmpxchg.h>
 #include <asm/io.h>
 #include <asm/vmx.h>
+#include "tlbsplit.h"
 
 /*
  * When setting this variable to true it enables Two-Dimensional-Paging
@@ -317,7 +318,7 @@ static int is_nx(struct kvm_vcpu *vcpu)
 
 static int is_shadow_present_pte(u64 pte)
 {
-	return pte & PT_PRESENT_MASK && !is_mmio_spte(pte);
+	return ((pte & PT_PRESENT_MASK) && !is_mmio_spte(pte)) || COULD_BE_SPLIT_PAGE(pte);
 }
 
 static int is_large_pte(u64 pte)
@@ -1135,6 +1136,11 @@ static u64 *rmap_get_next(struct rmap_it
 
 static void drop_spte(struct kvm *kvm, u64 *sptep)
 {
+	if (COULD_BE_SPLIT_PAGE(*sptep)) {
+	   //tlbs debug
+		printk(KERN_WARNING "drop_spte: got something that looks like split page in setter spte:0x%llx checkerfunc:%d\n",*sptep,split_tlb_has_split_page(kvm,sptep));
+		WARN_ON(1);
+	}
 	if (mmu_spte_clear_track_bits(sptep))
 		rmap_remove(kvm, sptep);
 }
@@ -1360,7 +1366,10 @@ static int kvm_unmap_rmapp(struct kvm *k
 	int need_tlb_flush = 0;
 
 	while ((sptep = rmap_get_first(*rmapp, &iter))) {
-		BUG_ON(!(*sptep & PT_PRESENT_MASK));
+		BUG_ON(!(*sptep & PT_PRESENT_MASK)&&!COULD_BE_SPLIT_PAGE(*sptep));
+		if (COULD_BE_SPLIT_PAGE(*sptep) && split_tlb_has_split_page(kvm,sptep)) {
+			printk(KERN_WARNING "kvm_unmap_rmapp: flipped page to exec 0x%llx\n",*sptep);
+		}
 		rmap_printk("kvm_rmap_unmap_hva: spte %p %llx gfn %llx (%d)\n",
 			     sptep, *sptep, gfn, level);
 
@@ -1511,7 +1520,7 @@ static int kvm_age_rmapp(struct kvm *kvm
 
 	for (sptep = rmap_get_first(*rmapp, &iter); sptep;
 	     sptep = rmap_get_next(&iter)) {
-		BUG_ON(!is_shadow_present_pte(*sptep));
+		BUG_ON(!is_shadow_present_pte(*sptep) && !split_tlb_has_split_page(kvm,sptep));
 
 		if (*sptep & shadow_accessed_mask) {
 			young = 1;
@@ -1541,7 +1550,7 @@ static int kvm_test_age_rmapp(struct kvm
 
 	for (sptep = rmap_get_first(*rmapp, &iter); sptep;
 	     sptep = rmap_get_next(&iter)) {
-		BUG_ON(!is_shadow_present_pte(*sptep));
+		BUG_ON(!is_shadow_present_pte(*sptep) && !split_tlb_has_split_page(kvm,sptep));
 
 		if (*sptep & shadow_accessed_mask) {
 			young = 1;
@@ -2187,6 +2196,11 @@ static bool mmu_page_zap_pte(struct kvm
 
 	pte = *spte;
 	if (is_shadow_present_pte(pte)) {
+		if (COULD_BE_SPLIT_PAGE(pte)&&split_tlb_has_split_page(kvm,spte)) {
+			printk(KERN_WARNING "mmu_page_zap_pte: zapping split page in read mode, flipped it to code 0x%llx\n", pte);
+			//split_tlb_flip_to_code(kvm,sp->gfn,spte);
+			pte = *spte;
+		}
 		if (is_last_spte(pte, sp->role.level)) {
 			drop_spte(kvm, spte);
 			if (is_large_pte(pte))
@@ -2532,8 +2546,18 @@ static int set_spte(struct kvm_vcpu *vcp
 	u64 spte;
 	int ret = 0;
 
-	if (set_mmio_spte(vcpu->kvm, sptep, gfn, pfn, pte_access))
+	struct kvm_splitpage* page = split_tlb_findpage(vcpu->kvm, gfn<<PAGE_SHIFT);
+
+	if (COULD_BE_SPLIT_PAGE(*sptep)) {
+	   //tlbs debug
+		printk(KERN_WARNING "set_spte: got something that looks like active split page in setter spte:0x%llx\n",*sptep);
+		WARN_ON(1);
+	}
+
+	if (set_mmio_spte(vcpu->kvm, sptep, gfn, pfn, pte_access)) {
+		WARN_ON(page!=NULL);
 		return 0;
+	}
 
 	spte = PT_PRESENT_MASK;
 	if (!speculative)
@@ -2598,6 +2622,10 @@ static int set_spte(struct kvm_vcpu *vcp
 	}
 
 set_pte:
+	if (page&&page->active) {
+		printk(KERN_WARNING "set_spte: adjusting spte to execute only :0x%llx\n",spte);
+		spte&=~(VMX_EPT_WRITABLE_MASK|VMX_EPT_READABLE_MASK);
+	}
 	if (mmu_spte_update(sptep, spte))
 		kvm_flush_remote_tlbs(vcpu->kvm);
 done:
@@ -2615,6 +2643,12 @@ static void mmu_set_spte(struct kvm_vcpu
 	pgprintk("%s: spte %llx write_fault %d gfn %llx\n", __func__,
 		 *sptep, write_fault, gfn);
 
+	if (COULD_BE_SPLIT_PAGE(*sptep)) {
+	   //tlbs debug
+		printk(KERN_WARNING "mmu_set_spte: got something that looks like split page in setter spte:0x%llx\n",*sptep);
+		WARN_ON(1);
+	}
+
 	if (is_rmap_spte(*sptep)) {
 		/*
 		 * If we overwrite a PTE page pointer with a 2MB PMD, unlink
@@ -2746,6 +2780,24 @@ static void direct_pte_prefetch(struct k
 	__direct_pte_prefetch(vcpu, sp, sptep);
 }
 
+u64* split_tlb_findspte(struct kvm_vcpu *vcpu,gfn_t gfn) {
+
+	struct kvm_shadow_walk_iterator iterator;
+	for_each_shadow_entry(vcpu, gfn << PAGE_SHIFT, iterator) {
+		int last = is_last_spte(*iterator.sptep, iterator.level);
+		int large = is_large_pte(*iterator.sptep);
+		if (last && !large) {
+			return iterator.sptep;
+		}
+		if (last && large) {
+			printk(KERN_WARNING "Found large page for 0x%llx spte:0x%llx level:%d\n",gfn << PAGE_SHIFT,*iterator.sptep,iterator.level);
+			return NULL;
+		}
+	}
+	return NULL;
+}
+
+
 static int __direct_map(struct kvm_vcpu *vcpu, gpa_t v, int write,
 			int map_writable, int level, gfn_t gfn, pfn_t pfn,
 			bool prefault)
